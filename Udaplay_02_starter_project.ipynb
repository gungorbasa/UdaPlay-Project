{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Platform': 'PlayStation 3', 'Name': 'Gran Turismo 5', 'YearOfRelease': 2010, 'Description': '[PlayStation 3] Gran Turismo 5 (2010) - A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.'}, {'Platform': 'PlayStation 5', 'Name': \"Marvel's Spider-Man 2\", 'YearOfRelease': 2023, 'Description': \"[PlayStation 5] Marvel's Spider-Man 2 (2023) - The sequel to the acclaimed Spider-Man game, featuring both Peter Parker and Miles Morales as playable characters.\"}, {'Platform': 'PlayStation 4', 'Name': \"Marvel's Spider-Man\", 'YearOfRelease': 2018, 'Description': \"[PlayStation 4] Marvel's Spider-Man (2018) - An open-world superhero game that lets players swing through New York City as Spider-Man, battling iconic villains.\"}, {'Platform': 'PlayStation 1', 'Name': 'Gran Turismo', 'YearOfRelease': 1997, 'Description': '[PlayStation 1] Gran Turismo (1997) - A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.'}, {'Platform': 'PlayStation 2', 'Name': 'Grand Theft Auto: San Andreas', 'YearOfRelease': 2004, 'Description': \"[PlayStation 2] Grand Theft Auto: San Andreas (2004) - An expansive open-world game set in the fictional state of San Andreas, following the story of Carl 'CJ' Johnson.\"}]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "@tool\n",
    "def retrieve_game(search: str):\n",
    "    \"\"\"\n",
    "    Semantic search: Finds matching games in the vector DB.\n",
    "\n",
    "    Args:\n",
    "        search (str): A question about the game industry (e.g., \"Games released on PS5 in 2022\").\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list where each element contains:\n",
    "            - Platform: str, the platform name (e.g., \"PlayStation 5\")\n",
    "            - Name: str, the game title\n",
    "            - YearOfRelease: str or int, release year\n",
    "            - Description: str, additional details about the game\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[search],\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    games = []\n",
    "    # Combine document text + metadata into structured records\n",
    "    for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        games.append({\n",
    "            \"Platform\": meta.get(\"Platform\", \"Unknown\"),\n",
    "            \"Name\": meta.get(\"Name\", \"Unknown\"),\n",
    "            \"YearOfRelease\": meta.get(\"YearOfRelease\", \"Unknown\"),\n",
    "            \"Description\": doc or meta.get(\"Description\", \"N/A\"),\n",
    "        })\n",
    "\n",
    "    return games\n",
    "\n",
    "print(retrieve_game(\"best game for playstation 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool\n",
    "    description: str\n",
    "\n",
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list[dict]) -> EvaluationReport:\n",
    "    \"\"\"\n",
    "    Evaluate the relevance of retrieved documents for a given question.\n",
    "\n",
    "    Args:\n",
    "        question (str): The original question from the user.\n",
    "        retrieved_docs (list[dict]): The documents retrieved from the vector database.\n",
    "\n",
    "    Returns:\n",
    "        dict: A report on the usefulness of the retrieved documents.\n",
    "    \"\"\"\n",
    "\n",
    "    context_str = \"\\n\".join([f\"{doc}\" for doc in retrieved_docs])\n",
    "    system_msg = (\n",
    "        \"You are an expert evaluator for retrieval-augmented generation (RAG). \"\n",
    "        \"Your task is to determine whether the provided retrieved documents are \"\n",
    "        \"sufficient, relevant, and reliable to answer the user's question. \"\n",
    "        \"Respond ONLY with a strict JSON object matching this schema:\\n\"\n",
    "        '{ \"useful\": <true|false>, \"description\": \"<detailed explanation and next actions>\" }'\n",
    "    )\n",
    "\n",
    "    user_msg = (\n",
    "        \"Question:\\n\"\n",
    "        f\"{question}\\n\\n\"\n",
    "        \"Retrieved Documents:\\n\"\n",
    "        f\"{context_str}\\n\\n\"\n",
    "        \"Evaluate if these documents are enough to respond to the question. \"\n",
    "        \"Give a detailed explanation so it is possible to take action to accept it or not. \"\n",
    "        \"If not sufficient, suggest what to retrieve next (e.g., more recent data, specific sections, different sources). \"\n",
    "        \"Return only JSON.\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    llm = LLM(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "    return llm.invoke(\n",
    "        input=[\n",
    "            SystemMessage(content=system_msg),\n",
    "            UserMessage(content=user_msg),\n",
    "        ],\n",
    "        response_format=EvaluationReport\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Create game_web_search tool\n# Please use Tavily client to search the web\n# Tool Docstring:\n#    Semantic search: Finds most results in the web\n#    args:\n#    - question: a question about game industry.\nfrom tavily import TavilyClient\n\ntavily_client = TavilyClient(api_key=TAVILY_API_KEY, api_base_url=\"https://api.tavily.com\")\n\n@tool\ndef game_web_search(question: str):\n    \"\"\"\n    Tool: game_web_search\n    Description:\n        Semantic search: Finds most relevant results from the web using Tavily.\n        This tool is optimized for game industry–related questions.\n\n    Args:\n        question (str): A natural language query about the game industry.\n\n    Returns:\n        list[dict]: A list of search results, each containing:\n            - title (str): The page title\n            - url (str): The source link\n            - content (str): The relevant snippet or summary from the page\n            - site_name (str): The website name for citation\n    \"\"\"\n    response = tavily_client.search(query=question, search_depth=\"basic\", max_results=5)\n\n    results = []\n    for r in response.get(\"results\", []):\n        # Extract site name from URL for better citation\n        import urllib.parse\n        parsed_url = urllib.parse.urlparse(r.get(\"url\", \"\"))\n        site_name = parsed_url.netloc.replace(\"www.\", \"\") if parsed_url.netloc else \"Unknown Source\"\n        \n        results.append({\n            \"title\": r.get(\"title\"),\n            \"url\": r.get(\"url\"),\n            \"content\": r.get(\"content\"),\n            \"site_name\": site_name,\n        })\n\n    return results"
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Create your Agent abstraction using StateMachine\n# Equip with an appropriate model\n# Craft a good set of instructions \n# Plug all Tools you developed\ntools = [\n    retrieve_game,\n    evaluate_retrieval,\n    game_web_search\n]\nagent = Agent(\n    model_name=\"gpt-4o-mini\",\n    tools=tools,\n    instructions = (\n        \"You are UdaPlay, an AI Research Agent specialized in the video game industry. \"\n        \"You always follow a Thought → Action → Answer pattern.\\n\\n\"\n\n        \"Execution plan:\\n\"\n        \"- Use Thought to reason about the user's question.\\n\"\n        \"- First, call the RAG tool `retrieve_game` to retrieve relevant knowledge from the vector database.\\n\"\n        \"- After using `retrieve_game`, always call the `evaluate_retrieval` tool to judge whether the retrieved documents \"\n        \"are sufficient and useful to answer the question.\\n\"\n        \"- If `evaluate_retrieval` reports that the documents are useful, use them to answer the question.\\n\"\n        \"- If `evaluate_retrieval` reports that the documents are not useful, then use the web search tool `game_web_search`.\\n\"\n        \"- If neither tool is available, or none of them provide a confident answer, respond with: \"\n        \"'I don't know the answer.'\\n\\n\"\n\n        \"Rules:\\n\"\n        \"- Always use `evaluate_retrieval` immediately after `retrieve_game`.\\n\"\n        \"- Never fabricate answers.\\n\"\n        \"- Only answer once you have confident information.\\n\"\n        \"- Always clearly separate Thought, Action, and Answer.\\n\\n\"\n\n        \"Citation Format:\\n\"\n        \"Always structure your final answer in JSON format:\\n\"\n        \"{\\n\"\n        '    \"answer\": \"Your detailed answer here\",\\n'\n        '    \"source\": \"web search\" or \"internal knowledge\",\\n'\n        '    \"reasoning\": \"Brief explanation of your reasoning process\",\\n'\n        '    \"citations\": {\\n'\n        '        \"web_sources\": [[\"https://example.com\", \"Site Name\"]],\\n'\n        '        \"local_sources\": [\"Platform: PlayStation, Game: Title, Year: 2023\"]\\n'\n        \"    }\\n\"\n        \"}\\n\\n\"\n\n        \"Citation Rules:\\n\"\n        \"- For web searches: Include both URL and site name in web_sources\\n\"\n        \"- For local searches: Include platform, game name, and year in local_sources\\n\"\n        \"- Always include your reasoning process\\n\"\n        \"- Specify whether answer came from web search or internal knowledge\\n\\n\"\n\n        f\"The actions you have are the Tools: {tools}.\\n\"\n        \"Your final Answer must be structured JSON with proper citations.\"\n    )\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e4be7",
   "metadata": {},
   "outputs": [],
   "source": "def log_tool_execution(messages):\n    tool_calls = [msg for msg in messages if hasattr(msg, 'role') and msg.role == 'tool']\n    for tool_msg in tool_calls:\n        tool_name = getattr(tool_msg, 'name', 'Unknown Tool')\n        print(f\"Tool used: {tool_name}\")\n        print(f\"Tool output: {getattr(tool_msg, 'content', 'N/A')[:100]}...\")\n\ndef format_citations(answer_text):\n    \"\"\"Extract and format citations from structured JSON answer\"\"\"\n    import json\n    try:\n        # Try to parse as JSON\n        answer_data = json.loads(answer_text)\n        if isinstance(answer_data, dict) and 'citations' in answer_data:\n            print(\"\\n=== CITATIONS ===\")\n            citations = answer_data['citations']\n            \n            if 'web_sources' in citations and citations['web_sources']:\n                print(\"Web Sources:\")\n                for source in citations['web_sources']:\n                    if isinstance(source, list) and len(source) >= 2:\n                        print(f\"  - {source[1]}: {source[0]}\")\n                    else:\n                        print(f\"  - {source}\")\n            \n            if 'local_sources' in citations and citations['local_sources']:\n                print(\"Local Sources:\")\n                for source in citations['local_sources']:\n                    print(f\"  - {source}\")\n            \n            print(f\"Source Type: {answer_data.get('source', 'Unknown')}\")\n            print(f\"Reasoning: {answer_data.get('reasoning', 'No reasoning provided')}\")\n            print(\"================\")\n        \n        return answer_data.get('answer', answer_text)\n    except json.JSONDecodeError:\n        # If not JSON, return original text\n        return answer_text"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Invoke your agent with enhanced citation reporting\n# - When Pokémon Gold and Silver was released?\n# - Which one was the first 3D platformer Mario game?\n# - Was Mortal Kombat X released for Playstation 5?\n\nprint(\"=== Query 1: When Pokémon Gold and Silver was released? ===\")\nresult = agent.invoke(query=\"When Pokémon Gold and Silver was released?\").get_final_state()\nlog_tool_execution(result[\"messages\"])\nanswer_content = result[\"messages\"][-1].content\nformatted_answer = format_citations(answer_content)\nprint(\"ANSWER:\", formatted_answer)\n\nprint(\"\\n=== Query 2: Which one was the first 3D platformer Mario game? ===\")\nresult = agent.invoke(query=\"Which one was the first 3D platformer Mario game?\").get_final_state()\nlog_tool_execution(result[\"messages\"])\nanswer_content = result[\"messages\"][-1].content\nformatted_answer = format_citations(answer_content)\nprint(\"ANSWER:\", formatted_answer)\n\nprint(\"\\n=== Query 3: Was Mortal Kombat X released for Playstation 5? ===\")\nresult = agent.invoke(query=\"Was Mortal Kombat X released for Playstation 5?\").get_final_state()\nlog_tool_execution(result[\"messages\"])\nanswer_content = result[\"messages\"][-1].content\nformatted_answer = format_citations(answer_content)\nprint(\"ANSWER:\", formatted_answer)"
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}